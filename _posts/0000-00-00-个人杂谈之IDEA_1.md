---
layout:     post
title:      个人杂谈之IDEA_1
date:       0000-01-01
author:     cyq
catalog: true
tags:
    - 个人杂谈

---



最近看到ACL2019的一篇论文《Compositional Questions Do Not Necessitate Multi-hop Reasoning》，这篇论文以HotpotQA数据集进行实验，想要说明即使一个单跳模型也可以处理部分组合问题。比如，有些看似是组合问题，但如果忽略问题中冗余的信息，它其实就是一个单跳问题，，或者通过确定答案的具体实体类型，就可以在非开放域的情况下（仅有部分候选文档）通过单跳计算得到答案。

个人感觉这篇论文的最大意义在于揭示目前的多跳QA数据集构造的缺陷之处，即模型可以找到一些漏洞，实际并没有学习到多跳推理能力。

同时也提出了一个研究点，即检索系统如何能够检索出更好的候选文档集合，使得组合问题真正需要多跳推理才能被解决，从而促使模型真正学到多跳推理能力。



------------------------------------------------- 进一步整理思路 （2020.02.19）--------------------------------------------------------

目前的QA领域的数据集情况看：

- 以SQuAD为例，数据集是先从wikipedia截取passage，再由人看了passage内容后提出question。当然这样的构造方式会花费大量人力，而且产生的问题过于简单，导致模型实际通过表面的字的匹配就可以找到答案，而并没有学到推理能力。。。。当然目前也开始有工作来研究如何用模型自动化生成question。
- 以Quasar-T、SearchQA、MAMARCO为例，这些数据集的构造方式都是收集用户在网上实际的搜索问题为question，然后通过Lunece、google、Bing等方式检索得到相关的sentence、document、passage甚至snnipet 作为context，然后再训练RC模型做答案抽取或生成。

总体来说，我们的任务是如何做好context的检索问题，找到尽量少的且相关的passage/snnipet，以有助于后期RC阶段得到最好的效果。（根据Quasar-T数据集的论文所述，随着context越多，虽然召回率更高，但导致RC模型的预测变得更困难，因为包含的噪声也越多）

从发展下一代搜索引擎的角度看，之后的应用场景会更贴近于上述的第二种模式，用户不管以文字、语音等何种方式在何种设备上输入query，所希望返回的都不是目前这样的document列表，而是先检索一些相关的passage/snnipet 后做RC，直接得到答案（抽取式或生成式）。



----------------------------------------- 根据进一步调研结果（2020.03.02）------------------------------------------------

挑战点：

- 如果在训练时都是远监督的正例，那训练出来的模型容易在测试时受不相关的段落的干扰。
- 对于需要多跳推理的问题，一次性很难从相关性的角度找全所需的段落。











部分已有工作：

- （端到端联合建模retrieval+RC）Latent Retrieval for Weakly Supervised Open Domain Question Answering，Lee等人，ACL2019
- （端到端联合建模retrieval+RC）Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index，Seo等人，ACL2019

以上两种方法都是把文档压缩到向量空间，丢失了词级别的信息。

- （未读）！！！Ranking paragraphs for improving answer recall in open-domain question answering. EMNLP2018
- Revealing the Importance of Semantic Retrieval for Machine Reading at Scale





结合KB和text作为外部知识进行QA：

- [ ] Neural architecture for question answering using a knowledge graph and web corpus. 2019
- [ ] More accurate question answering on freebase. 2015





